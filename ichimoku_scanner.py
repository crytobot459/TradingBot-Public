import ccxt
import pandas as pd
import numpy as np
import talib.abstract as ta
import warnings
from datetime import datetime
from typing import Dict, Any, Optional, Tuple, List
import random
from collections import defaultdict
import logging
import asyncio
EXCHANGE = 'binance'
QUOTE_CURRENCY = 'USDT'
TIMEFRAMES = ['4h', '1h', '15m', '5m']
MIN_DAILY_VOLUME_USDT = 3000000
TOP_N_RESULTS = 10
BEST_PICKS_COUNT = 3
MAX_PRICE_EXTENSION_PERCENT_1H = 8.0
MIN_SAFETY_MARGIN_PERCENT = 0.75
MIN_MONTHLY_CANDLES_FOR_WHITELIST = 6
TOP_CMC_COINS = ['ETH', 'BNB', 'SOL', 'DOGE', 'MATIC', 'ADA', 'LINK', 'XRP', 'AVAX', 'XLM', 'SUI', 'BCH', 'HBAR', 'LTC', 'DOT']
STABLECOIN_LIST = ['USDC', 'USTC', 'PAXG', 'TUSD', 'FDUSD', 'DAI', 'BUSD', 'USDP', 'USUAL', 'XUSD', 'WBETH', 'EUR', 'EURI', 'USD1', 'WBTC', 'USDE', 'TRX', 'PEPE']
BTC_SYMBOL = 'BTC/USDT'
FILTER_THRESHOLDS = {'bullish': 10.0, 'neutral': 5.0, 'bearish': 3.0}
BTC_PUMP_FILTER_THRESHOLD_24H = 4.0
BTC_PUMP_RSI_THRESHOLD_4H = 75
MAX_ENTRY_DEVIATION_PERCENT = 2.5
MIN_SAFETY_MARGIN_PERCENT = 0.75
WARHORSE_BYPASS_ENABLED = True
WARHORSE_CANDIDATE_MIN_VOLUME_FACTOR = 3.0
WARHORSE_CANDIDATE_MIN_RANGE_POSITION = 0.85
WARHORSE_CANDIDATE_MAX_24H_CHANGE = 40.0
MAX_PRE_BREAKOUT_DEVIATION_PERCENT = 4.0
ETH_SYMBOL = 'ETH/USDT'
warnings.filterwarnings('ignore', category=RuntimeWarning)

def initialize_exchange(exchange_id: str) -> Optional[ccxt.Exchange]:
    """Create and connect to the exchange, only use the SPOT market.
v2.0: Always specify 'defaultType': 'spot' to be 100% sure not to get it wrong
      data from the Futures or Perpetual market."""
    try:
        exchange_options = {'options': {'defaultType': 'spot'}}
        exchange = getattr(ccxt, exchange_id)(exchange_options)
        exchange.load_markets()
        print(f'Kh·ªüi t·∫°o s√†n {exchange_id} ·ªü ch·∫ø ƒë·ªô SPOT th√†nh c√¥ng.')
        return exchange
    except Exception as e:
        print(f'L·ªñI NGHI√äM TR·ªåNG khi kh·ªüi t·∫°o s√†n {exchange_id} ·ªü ch·∫ø ƒë·ªô SPOT: {e}')
        return None

def _get_dynamic_tf_analysis(df: pd.DataFrame, lookback: int=5) -> Dict[str, Any]:
    """In-depth momentum analysis function v2.1 - Identifying Exhaustion Signals.
- Divide RSI zones in more detail (strong, overbought) for more accurate interpretation.
- Able to detect when "Buying momentum is weakening" even when RSI is still present
  in the strong zone (e.g. 60-70), resolves the user reported issue."""
    if df.empty or len(df) < lookback + 1:
        return {'state': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu', 'rsi_val': 0, 'adx_val': 0, 'rsi_slope': 0, 'adx_slope': 0, 'momentum_verdict': 'Kh√¥ng x√°c ƒë·ªãnh', 'full_analysis_string': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu'}
    last_row = df.iloc[-1]
    close, ema50, ema200, rsi, adx = (last_row['close'], last_row['ema_50'], last_row['ema_200'], last_row['rsi'], last_row['adx'])
    ADX_TRENDING, RSI_BULLISH, RSI_BEARISH = (23, 55, 45)
    state = 'TRUNG L·∫¨P'
    if close > ema50 > ema200 and adx > ADX_TRENDING and (rsi > RSI_BULLISH):
        state = 'TƒÇNG M·∫†NH'
    elif close < ema50 < ema200 and adx > ADX_TRENDING and (rsi < RSI_BEARISH):
        state = 'GI·∫¢M M·∫†NH'
    elif ema50 < ema200 and close > ema50 and (rsi > RSI_BULLISH):
        state = 'PH·ª§C H·ªíI T·ª™ ƒê√ÅY'
    elif close > ema50 > ema200:
        state = 'T√çCH L≈®Y TR√äN (Uptrend y·∫øu)'
    elif ema50 > ema200 and close < ema50:
        state = 'ƒêI·ªÄU CH·ªàNH (trong Uptrend)'
    elif close < ema50 < ema200:
        state = 'XU H∆Ø·ªöNG GI·∫¢M'
    elif adx < 20:
        state = 'ƒêI NGANG (Sideways)'
    rsi_series = df['rsi'].tail(lookback).values
    adx_series = df['adx'].tail(lookback).values
    x_axis = np.arange(len(rsi_series))
    rsi_slope = np.polyfit(x_axis, rsi_series, 1)[0]
    adx_slope = np.polyfit(x_axis, adx_series, 1)[0]
    rsi_verdict = ''
    if rsi < 35:
        if rsi_slope > 0.4:
            rsi_verdict = '√Åp l·ª±c b√°n gi·∫£m.'
        elif rsi_slope < -0.4:
            rsi_verdict = '√Åp l·ª±c b√°n tƒÉng m·∫°nh.'
        else:
            rsi_verdict = 'ƒêang t√¨m ƒë√°y.'
    elif rsi > 68:
        if rsi_slope < -0.4:
            rsi_verdict = 'ƒê√† mua suy y·∫øu (t·ª´ v√πng qu√° mua).'
        elif rsi_slope > 0.4:
            rsi_verdict = 'ƒê√† mua tƒÉng r·∫•t m·∫°nh (r·ªßi ro cao).'
        else:
            rsi_verdict = 'ƒêang t√¨m ƒë·ªânh.'
    elif rsi > 58:
        if rsi_slope < -0.4:
            rsi_verdict = 'ƒê√† mua ƒëang y·∫øu d·∫ßn (d·∫•u hi·ªáu ki·ªát s·ª©c).'
        elif rsi_slope > 0.4:
            rsi_verdict = 'ƒê√† mua duy tr√¨ t·ªët.'
        else:
            rsi_verdict = 'ƒê·ªông l∆∞·ª£ng ch·ªØng l·∫°i ·ªü v√πng m·∫°nh.'
    elif rsi_slope > 0.5:
        rsi_verdict = 'ƒê√† mua ƒëang tƒÉng.'
    elif rsi_slope < -0.5:
        rsi_verdict = 'ƒê√† b√°n ƒëang tƒÉng.'
    else:
        rsi_verdict = 'ƒê·ªông l∆∞·ª£ng ch·ªØng l·∫°i.'
    adx_verdict = ''
    if adx > ADX_TRENDING:
        if adx_slope > 0.3:
            adx_verdict = 'Xu h∆∞·ªõng hi·ªán t·∫°i m·∫°nh l√™n.'
        elif adx_slope < -0.3:
            adx_verdict = 'Xu h∆∞·ªõng hi·ªán t·∫°i y·∫øu ƒëi.'
        else:
            adx_verdict = 'Xu h∆∞·ªõng duy tr√¨.'
    elif adx_slope > 0.3:
        adx_verdict = 'S·∫Øp c√≥ xu h∆∞·ªõng m·ªõi.'
    else:
        adx_verdict = 'Ti·∫øp t·ª•c ƒëi ngang.'
    momentum_verdict = f'{rsi_verdict} {adx_verdict}'
    full_analysis_string = f'{state} (RSI: {rsi:.0f}, ADX: {adx:.0f}) | ƒê·ªông l∆∞·ª£ng: {momentum_verdict.strip()}'
    return {'state': state, 'rsi_val': rsi, 'adx_val': adx, 'rsi_slope': rsi_slope, 'adx_slope': adx_slope, 'momentum_verdict': momentum_verdict, 'full_analysis_string': full_analysis_string}

def _evaluate_market_factors(*args, **kwargs):
    """Help Function v8.4 - The Brain Scores & Fixes "Losing Momentum" Logic Errors.

UPDATE:
- Refactor the state determination logic. The weak ADX test (< 22) is okay
  execute AFTER defining the original EMA structure, allowing it to override
  and accurately determine the state of "Losing Momentum" in all contexts (uptrend, downtrend,
  recovery), completely resolving user reported errors."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def analyze_market_context(*args, **kwargs):
    """MARKET CONTEXT ANALYSIS FUNCTION v8.5 - Multi-Frame ADX Burst Sensor.

UPDATE (According to user request):
- Extend ADX burst detection logic to 3 strategic time frames: 4h, 1h, 15m.
- Calculate ADX change and DMI status for each frame.
- Pack all burst analysis results into a new dictionary called `adx_burst_analysis`
  so that automation_manager can handle it flexibly.
- BUGFIX: Explicitly convert `is_bearish_dmi` to `bool` for JSON compatibility."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def get_altcoin_market_snapshot(tickers: Dict[str, Any]) -> Dict[str, Any]:
    """v3.1 -- Fix JSON Serializable for boolean values \u200b\u200bfrom NumPy.
- Explicitly convert boolean values in `market_regime` from `numpy.bool_`
  to Python's native `bool` to ensure compatibility when saving JSON files."""
    snapshot = {'total_analyzed': 0, 'performance_dist': {'gainers': 0, 'losers': 0, 'neutral': 0}, 'gainers_percentage': 0.0, 'losers_percentage': 0.0, 'median_change_24h': 0.0, 'avg_gainer_change': 0.0, 'avg_loser_change': 0.0, 'volatility_index': 0.0, 'range_position_index': 0.0, 'breakout_strength_index': 0.0, 'verdict': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu.', 'market_regime': {}}
    valid_altcoins = {s: t for s, t in tickers.items() if s.endswith(f'/{QUOTE_CURRENCY}') and t and (t.get('quoteVolume', 0) > MIN_DAILY_VOLUME_USDT) and ('UP/' not in s) and ('DOWN/' not in s) and (s.split('/')[0] not in STABLECOIN_LIST) and (s != BTC_SYMBOL) and (s != ETH_SYMBOL) and all((k in t and t[k] is not None for k in ['percentage', 'open', 'high', 'low', 'last']))}
    if not valid_altcoins:
        return snapshot
    data = []
    for symbol, ticker in valid_altcoins.items():
        price_range = ticker['high'] - ticker['low']
        data.append({'symbol': symbol, 'change_24h': ticker.get('percentage', 0.0), 'atr_percent': (ticker['high'] - ticker['low']) / ticker['open'] * 100 if ticker['open'] > 0 else 0, 'position_in_range': (ticker['last'] - ticker['low']) / price_range if price_range > 0 else 0.5})
    df = pd.DataFrame(data)
    if df.empty:
        return snapshot
    total_analyzed = len(df)
    gainers_df = df[df['change_24h'] > 1.0]
    losers_df = df[df['change_24h'] < -1.0]
    gainers = len(gainers_df)
    losers = len(losers_df)
    neutral = total_analyzed - gainers - losers
    snapshot.update({'total_analyzed': total_analyzed, 'performance_dist': {'gainers': gainers, 'losers': losers, 'neutral': neutral}, 'gainers_percentage': gainers / total_analyzed * 100 if total_analyzed > 0 else 0.0, 'losers_percentage': losers / total_analyzed * 100 if total_analyzed > 0 else 0.0, 'median_change_24h': df['change_24h'].median(), 'avg_gainer_change': gainers_df['change_24h'].mean() if not gainers_df.empty else 0.0, 'avg_loser_change': losers_df['change_24h'].mean() if not losers_df.empty else 0.0, 'volatility_index': df['atr_percent'].median(), 'range_position_index': df['position_in_range'].mean() * 100, 'breakout_strength_index': (df['position_in_range'] > 0.9).sum() / total_analyzed * 100 if total_analyzed > 0 else 0.0})
    for key, value in snapshot.items():
        if isinstance(value, (np.int64, np.int32)):
            snapshot[key] = int(value)
        elif isinstance(value, (np.float64, np.float32)):
            snapshot[key] = float(value)
    regime_numpy = {'is_trending_up': snapshot['gainers_percentage'] > 60 and snapshot['median_change_24h'] > 1.5, 'is_trending_down': snapshot['losers_percentage'] > 60 and snapshot['median_change_24h'] < -1.5, 'is_gainer_dominated': snapshot['gainers_percentage'] > max(40, snapshot['losers_percentage'] * 1.8), 'is_loser_dominated': snapshot['losers_percentage'] > max(40, snapshot['gainers_percentage'] * 1.8), 'is_high_volatility': snapshot['volatility_index'] > 8.0, 'is_low_volatility': snapshot['volatility_index'] < 3.5, 'has_strong_momentum': snapshot['range_position_index'] > 65 and snapshot['breakout_strength_index'] > 15, 'has_weak_momentum': snapshot['range_position_index'] < 35}
    regime = {key: bool(value) for key, value in regime_numpy.items()}
    snapshot['market_regime'] = regime
    if regime['is_trending_up']:
        verdict = f'TH·ªä TR∆Ø·ªúNG TƒÇNG TR∆Ø·ªûNG: {snapshot['gainers_percentage']:.0f}% s·ªë coin tƒÉng gi√°, l·ª±c mua lan t·ªèa.'
    elif regime['is_trending_down']:
        verdict = f'TH·ªä TR∆Ø·ªúNG SUY Y·∫æU: {snapshot['losers_percentage']:.0f}% s·ªë coin gi·∫£m gi√°, √°p l·ª±c b√°n lan t·ªèa.'
    elif regime['is_gainer_dominated'] and regime['has_strong_momentum']:
        verdict = f'TH·ªä TR∆Ø·ªúNG N√ìNG: Phe mua chi·∫øm ∆∞u th·∫ø r√µ r·ªát ({snapshot['gainers_percentage']:.0f}%) v·ªõi ƒë·ªông l∆∞·ª£ng m·∫°nh.'
    elif regime['is_loser_dominated']:
        verdict = f'TH·ªä TR∆Ø·ªúNG L·∫†NH: R·ªßi ro cao, phe b√°n ƒëang ki·ªÉm so√°t ({snapshot['losers_percentage']:.0f}%).'
    elif regime['is_low_volatility']:
        verdict = f'TH·ªä TR∆Ø·ªúNG T√çCH L≈®Y: Bi·∫øn ƒë·ªông th·∫•p (ATR {snapshot['volatility_index']:.1f}%), c√≥ th·ªÉ s·∫Øp c√≥ bi·∫øn ƒë·ªông m·∫°nh.'
    else:
        verdict = 'TH·ªä TR∆Ø·ªúNG PH√ÇN H√ìA: Kh√¥ng c√≥ xu h∆∞·ªõng r√µ r√†ng, c·∫ßn l·ª±a ch·ªçn c·∫©n th·∫≠n.'
    snapshot['verdict'] = verdict
    return snapshot

def get_all_usdt_pairs(exchange: ccxt.Exchange) -> Tuple[List[str], Dict[str, Any], Dict[str, Any]]:
    """v2.7 - Use static Top CoinMarketCap list.
- UPDATE:
  - Completely remove logic for calculating top 15 by volume.
  - Replaced with a predefined list of top coins (TOP_CMC_COINS).
  - This ensures the bot is always monitoring a stable group of "blue-chip" coins."""
    market_context = analyze_market_context(exchange)
    base_threshold = market_context['btc_context']['filter_threshold']
    all_pairs_for_scan = []
    bypass_count = 0
    try:
        print('ƒêang t·∫£i d·ªØ li·ªáu ticker t·ª´ s√†n...')
        tickers = exchange.fetch_tickers()
        print('T·∫£i d·ªØ li·ªáu ticker ho√†n t·∫•t.')
        top_15_cmc_pairs = [f'{coin}/{QUOTE_CURRENCY}' for coin in TOP_CMC_COINS]
        print(f'  -> [TH√ÄNH C√îNG] ƒê√£ x√°c ƒë·ªãnh danh s√°ch theo d√µi Top CoinMarketCap: {', '.join(top_15_cmc_pairs)}')
        for symbol, ticker in tickers.items():
            try:
                market_info = exchange.market(symbol)
            except ccxt.BadSymbol:
                continue
            is_valid_active_spot_market = market_info.get('spot', False) and market_info.get('active', False)
            if not (symbol.endswith(f'/{QUOTE_CURRENCY}') and ticker and is_valid_active_spot_market):
                continue
            base_currency = symbol.split('/')[0]
            if 'UP/' in symbol or 'DOWN/' in symbol or base_currency in STABLECOIN_LIST:
                continue
            quote_volume = ticker.get('quoteVolume', 0)
            change_24h = ticker.get('percentage')
            if not quote_volume or quote_volume < MIN_DAILY_VOLUME_USDT or change_24h is None:
                continue
            if change_24h <= market_context['btc_context']['filter_threshold']:
                all_pairs_for_scan.append(symbol)
                continue
            if WARHORSE_BYPASS_ENABLED and market_context['btc_context']['filter_threshold'] < change_24h <= WARHORSE_CANDIDATE_MAX_24H_CHANGE:
                has_high_volume = quote_volume > MIN_DAILY_VOLUME_USDT * WARHORSE_CANDIDATE_MIN_VOLUME_FACTOR
                high_24h, low_24h, last_price = (ticker.get('high'), ticker.get('low'), ticker.get('last'))
                has_sustained_momentum = False
                if high_24h and low_24h and last_price:
                    price_range = high_24h - low_24h
                    if price_range > 0 and (last_price - low_24h) / price_range >= WARHORSE_CANDIDATE_MIN_RANGE_POSITION:
                        has_sustained_momentum = True
                if has_high_volume and has_sustained_momentum:
                    all_pairs_for_scan.append(symbol)
                    bypass_count += 1
        altcoin_snapshot = get_altcoin_market_snapshot(tickers)
        print(f'\n--- Ph√¢n t√≠ch S·ª©c n√≥ng Altcoin (m·∫´u {altcoin_snapshot.get('total_analyzed', 0)} c·∫∑p) ---')
        if bypass_count > 0:
            print(f"  -> C∆° ch·∫ø 'V∆∞·ª£t R√†o' ƒë√£ ƒë·∫∑c c√°ch cho {bypass_count} m√£ c√≥ d·∫•u hi·ªáu leader.")
        print(f'\nL·ªçc ho√†n t·∫•t. T√¨m th·∫•y {len(all_pairs_for_scan)} c·∫∑p h·ª£p l·ªá ƒë·ªÉ qu√©t s√¢u.')
        summary = {'market_context': market_context, 'total_pairs_in_universe': len(all_pairs_for_scan), 'altcoin_snapshot': altcoin_snapshot, 'tickers': tickers, 'top_15_by_volume': top_15_cmc_pairs}
        return (all_pairs_for_scan, summary, tickers)
    except Exception as e:
        print(f'L·ªñI NGHI√äM TR·ªåNG khi l·∫•y danh s√°ch c·∫∑p giao d·ªãch: {e}')
        empty_context = {'btc_context': {}, 'eth_context': {}}
        return ([], {'market_context': empty_context, 'total_pairs_in_universe': 0, 'altcoin_snapshot': {}, 'tickers': {}, 'top_15_by_volume': []}, {})

def fetch_ohlcv_data(exchange: ccxt.Exchange, pair: str, timeframe: str, limit: int=300) -> Optional[pd.DataFrame]:
    try:
        if not exchange.has['fetchOHLCV']:
            return None
        ohlcv = exchange.fetch_ohlcv(pair, timeframe, limit=limit)
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        return df.set_index('timestamp')
    except Exception:
        return None

def add_relative_strength_data(df: pd.DataFrame, btc_df: pd.DataFrame) -> Optional[pd.DataFrame]:
    if df is None:
        return None
    if df.empty or btc_df is None or btc_df.empty or ('close' not in btc_df.columns):
        df['rs'] = np.nan
        df['rs_ma'] = np.nan
        return df
    df.index = pd.to_datetime(df.index)
    btc_df.index = pd.to_datetime(btc_df.index)
    data = pd.concat([df['close'], btc_df['close']], axis=1, keys=['asset', 'btc'])
    data['btc'] = data['btc'].reindex(data.index, method='ffill')
    data.dropna(subset=['asset'], inplace=True)
    if data.empty or 'btc' not in data.columns or data['btc'].isnull().all():
        df['rs'] = np.nan
        df['rs_ma'] = np.nan
        return df
    data['rs'] = data['asset'] / data['btc']
    data['rs_ma'] = ta.SMA(data['rs'], timeperiod=50)
    df['rs'] = data['rs']
    df['rs_ma'] = data['rs_ma']
    return df

def calculate_indicators(df: pd.DataFrame) -> Optional[pd.DataFrame]:
    """Indicator calculation function v2.0 - Fix Ichimoku Cloud calculation logic error.
- Ensure shifted indicators are calculated on the data set
  fully before removing NaN rows, which preserves forecast data."""
    if df is None or len(df) < 100:
        return None
    df['atr'] = ta.ATR(df, timeperiod=14)
    df['vol_ma_20'] = ta.SMA(df['volume'], timeperiod=20)
    df['ema_7'] = ta.EMA(df['close'], timeperiod=7)
    df['ema_8'] = ta.EMA(df['close'], timeperiod=8)
    df['ema_9'] = ta.EMA(df['close'], timeperiod=9)
    df['ema_21'] = ta.EMA(df, timeperiod=21)
    df['ema_50'] = ta.EMA(df, timeperiod=50)
    df['ema_200'] = ta.EMA(df, timeperiod=200)
    tenkan_period, kijun_period, senkou_b_period, displacement = (9, 26, 52, 26)
    df['tenkan_sen'] = (df['high'].rolling(window=tenkan_period).max() + df['low'].rolling(window=tenkan_period).min()) / 2
    df['kijun_sen'] = (df['high'].rolling(window=kijun_period).max() + df['low'].rolling(window=kijun_period).min()) / 2
    senkou_a_raw = (df['tenkan_sen'] + df['kijun_sen']) / 2
    df['senkou_a'] = senkou_a_raw.shift(displacement - 1)
    senkou_b_raw = (df['high'].rolling(window=senkou_b_period).max() + df['low'].rolling(window=senkou_b_period).min()) / 2
    df['senkou_b'] = senkou_b_raw.shift(displacement - 1)
    df['chikou_span'] = df['close'].shift(-(displacement - 1))
    df['adx'] = ta.ADX(df, timeperiod=14)
    df['plus_di'] = ta.PLUS_DI(df, timeperiod=14)
    df['minus_di'] = ta.MINUS_DI(df, timeperiod=14)
    bollinger = ta.BBANDS(df, timeperiod=20, nbdevup=2.0, nbdevdn=2.0)
    df['bb_upper'] = bollinger['upperband']
    df['bb_middle'] = bollinger['middleband']
    df['bb_lower'] = bollinger['lowerband']
    df['bb_width'] = np.where(df['bb_middle'] > 0, (df['bb_upper'] - df['bb_lower']) / df['bb_middle'], 0)
    df['bbw_percentile'] = df['bb_width'].rolling(100).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False) * 100
    df['rsi'] = ta.RSI(df, timeperiod=14)
    df['rsi_21'] = ta.RSI(df, timeperiod=21)
    df['cdl_shootingstar'] = ta.CDLSHOOTINGSTAR(df)
    df['cdl_hangingman'] = ta.CDLHANGINGMAN(df)
    df['cdl_engulfing'] = ta.CDLENGULFING(df)
    df['ma_trend'] = ta.EMA(df, timeperiod=27)
    df['ma_trend_rising'] = df['ma_trend'] > df['ma_trend'].shift(1)
    df['body_size'] = abs(df['close'] - df['open'])
    df['body_size_ma'] = df['body_size'].rolling(window=20).mean()
    df['local_high_20'] = df['high'].rolling(window=20).max().shift(1)
    df['cdl_hammer'] = ta.CDLHAMMER(df)
    df['cdl_doji'] = ta.CDLDOJI(df)
    df['cdl_piercing'] = ta.CDLPIERCING(df)
    stoch = ta.STOCH(df, fastk_period=14, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)
    df['slowk'] = stoch['slowk']
    df['slowd'] = stoch['slowd']
    df.dropna(subset=['atr', 'vol_ma_20', 'ema_200', 'tenkan_sen', 'kijun_sen', 'adx', 'bb_middle', 'rsi', 'slowk', 'slowd'], inplace=True)
    if df.empty:
        return None
    return df

def _calculate_btc_volatility(df: pd.DataFrame, atr_period: int=14, atr_ma_period: int=50) -> Dict[str, Any]:
    """Volatility analysis based on ATR.
Compare the short-term ATR with the long-term average ATR to determine
whether volatility is increasing, decreasing, or stable."""
    if df is None or len(df) < atr_ma_period or 'atr' not in df.columns:
        return {'state': 'Kh√¥ng x√°c ƒë·ªãnh', 'atr_value': 0, 'ratio': 1.0}
    df['atr_ma'] = ta.SMA(df['atr'], timeperiod=atr_ma_period)
    last_atr = df['atr'].iloc[-1]
    avg_atr = df['atr_ma'].iloc[-1]
    if avg_atr == 0:
        return {'state': 'B√¨nh th∆∞·ªùng', 'atr_value': last_atr, 'ratio': 1.0}
    ratio = last_atr / avg_atr
    state = 'B√¨nh th∆∞·ªùng'
    if ratio > 1.25:
        state = 'M·ªü r·ªông'
    elif ratio < 0.75:
        state = 'Thu h·∫πp'
    return {'state': state, 'atr_value': last_atr, 'ratio': ratio}

def _calculate_scenario_probability(btc_context: Dict[str, Any]) -> Dict[str, Any]:
    """Estimate the probability of success for the main scenario based on convergence
of analytical factors."""
    base_prob = 50.0
    factors = []
    state_4h = btc_context.get('analysis_4h', '')
    if 'TƒÇNG M·∫†NH' in state_4h:
        base_prob += 15
        factors.append('(+) C·∫•u tr√∫c 4H tƒÉng m·∫°nh')
    elif 'GI·∫¢M M·∫†NH' in state_4h or 'XU H∆Ø·ªöNG GI·∫¢M' in state_4h:
        base_prob -= 15
        factors.append('(-) C·∫•u tr√∫c 4H gi·∫£m m·∫°nh')
    mom_4h = btc_context.get('momentum_verdict_4h', '')
    mom_1h = btc_context.get('momentum_verdict_1h', '')
    if ('MUA' in mom_1h or 'TƒÇNG' in mom_1h) and ('MUA' in mom_4h or 'TƒÇNG' in mom_4h):
        base_prob += 10
        factors.append('(+) ƒê·ªông l∆∞·ª£ng 1H-4H ƒë·ªìng thu·∫≠n tƒÉng')
    elif ('B√ÅN' in mom_1h or 'GI·∫¢M' in mom_1h) and ('B√ÅN' in mom_4h or 'GI·∫¢M' in mom_4h):
        base_prob -= 10
        factors.append('(-) ƒê·ªông l∆∞·ª£ng 1H-4H ƒë·ªìng thu·∫≠n gi·∫£m')
    else:
        factors.append('(~) ƒê·ªông l∆∞·ª£ng kh√¥ng ƒë·ªìng thu·∫≠n')
    vol_1h_state = btc_context.get('volatility_1h', {}).get('state', '')
    prediction_dir = btc_context.get('price_prediction', {}).get('direction', '')
    if vol_1h_state == 'M·ªü r·ªông' and prediction_dir in ['TƒÇNG', 'GI·∫¢M']:
        base_prob += 5
        factors.append('(+) Bi·∫øn ƒë·ªông ·ªßng h·ªô xu h∆∞·ªõng')
    elif vol_1h_state == 'Thu h·∫πp':
        base_prob -= 5
        factors.append('(-) Bi·∫øn ƒë·ªông th·∫•p, r·ªßi ro ph√° v·ª° gi·∫£')
    conclusion = btc_context.get('conclusion', '')
    if 'ƒê·∫¢O CHI·ªÄU' in conclusion or 'B√ÅN TH√ÅO' in conclusion:
        base_prob -= 20
        factors.append('(-) C·∫£nh b√°o r·ªßi ro cao (Ph√¢n k·ª≥/B√°n th√°o)')
    final_prob = max(10.0, min(90.0, base_prob))
    verdict = 'TRUNG B√åNH'
    if final_prob >= 70:
        verdict = 'CAO'
    elif final_prob >= 60:
        verdict = 'KH√Å'
    elif final_prob < 40:
        verdict = 'TH·∫§P'
    return {'probability_percent': final_prob, 'verdict': verdict, 'factors': factors}

def analyze_rsi_adx_statistical_model(df: pd.DataFrame, timeframe_name: str) -> Dict[str, Any]:
    """STATISTICAL MODEL RSI + ADX v1.0 - Probabilistic Forecasting Brain.

Analyze the last 5 sessions to determine the status and trend of momentum,
From there calculate the probability of increase/decrease and make recommendations.

Returns:
    A dictionary contains probabilities, recommendations, and analytical evidence."""
    analysis = {'probability_increase': 50.0, 'recommendation': 'CH·ªú', 'verdict': 'Trung l·∫≠p', 'evidence': []}
    if df is None or len(df) < 20:
        analysis['verdict'] = 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu'
        analysis['evidence'].append('Thi·∫øu d·ªØ li·ªáu l·ªãch s·ª≠.')
        return analysis
    recent_df = df.tail(5)
    if len(recent_df) < 5:
        analysis['verdict'] = 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu g·∫ßn ƒë√¢y'
        analysis['evidence'].append('Kh√¥ng ƒë·ªß 5 n·∫øn ƒë·ªÉ ph√¢n t√≠ch chu·ªói.')
        return analysis
    last_candle = recent_df.iloc[-1]
    x_axis = np.arange(5)
    rsi_slope = np.polyfit(x_axis, recent_df['rsi'], 1)[0]
    adx_slope = np.polyfit(x_axis, recent_df['adx'], 1)[0]
    total_score = 0
    rsi_score = 0
    current_rsi = last_candle['rsi']
    if current_rsi > 65:
        rsi_score -= 15
        analysis['evidence'].append(f'RSI Qu√° mua ({current_rsi:.1f})')
    elif current_rsi > 55:
        rsi_score += 20
        analysis['evidence'].append(f'RSI ƒê√† tƒÉng t·ªët ({current_rsi:.1f})')
    elif current_rsi < 35:
        rsi_score += 10
        analysis['evidence'].append(f'RSI Qu√° b√°n ({current_rsi:.1f})')
    elif current_rsi < 45:
        rsi_score -= 15
        analysis['evidence'].append(f'RSI ƒê√† gi·∫£m ({current_rsi:.1f})')
    else:
        analysis['evidence'].append(f'RSI Trung l·∫≠p ({current_rsi:.1f})')
    if rsi_slope > 1.0:
        rsi_score += 25
        analysis['evidence'].append('Chu·ªói RSI tƒÉng m·∫°nh')
    elif rsi_slope > 0.3:
        rsi_score += 15
        analysis['evidence'].append('Chu·ªói RSI tƒÉng nh·∫π')
    elif rsi_slope < -1.0:
        rsi_score -= 25
        analysis['evidence'].append('Chu·ªói RSI gi·∫£m m·∫°nh')
    elif rsi_slope < -0.3:
        rsi_score -= 15
        analysis['evidence'].append('Chu·ªói RSI gi·∫£m nh·∫π')
    total_score += rsi_score * 0.45
    adx_score = 0
    current_adx = last_candle['adx']
    plus_di = last_candle['plus_di']
    minus_di = last_candle['minus_di']
    is_trending = current_adx > 23
    is_bullish_trend = is_trending and plus_di > minus_di
    is_bearish_trend = is_trending and minus_di > plus_di
    if is_bullish_trend:
        adx_score += 30
        analysis['evidence'].append(f'ADX x√°c nh·∫≠n TƒÉng ({current_adx:.1f})')
        if adx_slope > 0.3:
            adx_score += 20
            analysis['evidence'].append('Xu h∆∞·ªõng tƒÉng m·∫°nh l√™n')
    elif is_bearish_trend:
        adx_score -= 30
        analysis['evidence'].append(f'ADX x√°c nh·∫≠n Gi·∫£m ({current_adx:.1f})')
        if adx_slope > 0.3:
            adx_score -= 20
            analysis['evidence'].append('Xu h∆∞·ªõng gi·∫£m m·∫°nh l√™n')
    else:
        adx_score -= 10
        analysis['evidence'].append(f'ADX kh√¥ng c√≥ xu h∆∞·ªõng ({current_adx:.1f})')
    total_score += adx_score * 0.55
    probability = 50.0 + total_score / 50.0 * 50.0
    analysis['probability_increase'] = max(0.0, min(100.0, probability))
    if analysis['probability_increase'] > 65:
        analysis['recommendation'] = '∆ØU TI√äN MUA SPOT'
        analysis['verdict'] = 'TƒÉng gi√°'
    elif analysis['probability_increase'] < 35:
        analysis['recommendation'] = 'CH·ªú'
        analysis['verdict'] = 'Gi·∫£m gi√°'
    else:
        analysis['recommendation'] = 'CH·ªú'
        analysis['verdict'] = 'Trung l·∫≠p'
    return analysis

def analyze_trend_cycle(df_1h: pd.DataFrame) -> Dict[str, Any]:
    """v2.0 - Refactored to use available data and provide more detailed analysis."""
    if len(df_1h) < 50 or not all((c in df_1h.columns for c in ['close', 'high', 'rsi', 'ema_50', 'ema_200'])):
        return {'stage': 'L·ªói D·ªØ Li·ªáu', 'score': 0, 'reason': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu ho·∫∑c thi·∫øu ch·ªâ b√°o c·∫ßn thi·∫øt'}
    recent_df = df_1h.tail(30).copy()
    if recent_df.empty:
        return {'stage': 'L·ªói D·ªØ Li·ªáu', 'score': 0, 'reason': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu g·∫ßn ƒë√¢y'}
    last = recent_df.iloc[-1]
    high_prices = recent_df['high']
    rsi_values = recent_df['rsi']
    price_peak_idx = high_prices.idxmax()
    is_bearish_divergence = False
    if price_peak_idx == high_prices.index[-1]:
        second_price_peak = high_prices.drop(price_peak_idx).max()
        if not pd.isna(second_price_peak):
            second_price_peak_idx = high_prices[high_prices == second_price_peak].index[-1]
            if last['high'] > second_price_peak and last['rsi'] < rsi_values.loc[second_price_peak_idx]:
                is_bearish_divergence = True
    is_overextended = last['close'] > last['ema_50'] * 1.15
    if is_bearish_divergence and is_overextended:
        return {'stage': 'S√≥ng Cu·ªëi', 'score': -30, 'reason': 'R·ªßi ro Ph√¢n k·ª≥ √¢m + Gi√° qu√° d√£n'}
    is_strong_uptrend = last['close'] > last['ema_50'] > last['ema_200']
    is_rsi_healthy = 55 < last['rsi'] < 70
    if is_strong_uptrend and is_rsi_healthy:
        return {'stage': 'S√≥ng Gi·ªØa', 'score': 10, 'reason': 'Xu h∆∞·ªõng tƒÉng tr∆∞·ªüng kh·ªèe m·∫°nh'}
    is_just_crossed_ema200 = df_1h.iloc[-2]['close'] < df_1h.iloc[-2]['ema_200'] and last['close'] > last['ema_200']
    if is_just_crossed_ema200 and (not is_strong_uptrend):
        return {'stage': 'S√≥ng ƒê·∫ßu', 'score': 5, 'reason': 'Giai ƒëo·∫°n ƒë·∫ßu c·ªßa xu h∆∞·ªõng'}
    is_consolidating_up = last['close'] > last['ema_50'] and last['rsi'] > 50
    if is_consolidating_up:
        return {'stage': 'T√≠ch L≈©y TƒÉng', 'score': 3, 'reason': 'T√≠ch l≈©y trong xu h∆∞·ªõng tƒÉng'}
    is_correcting = last['close'] < last['ema_50'] and last['ema_50'] > last['ema_200']
    if is_correcting:
        return {'stage': 'ƒêi·ªÅu Ch·ªânh', 'score': -5, 'reason': 'ƒêi·ªÅu ch·ªânh trong xu h∆∞·ªõng tƒÉng'}
    return {'stage': 'ƒêi Ngang', 'score': 0, 'reason': 'ƒêi ngang tr√™n n·ªÅn t·∫£ng vƒ© m√¥'}

def find_bullish_divergence(*args, **kwargs):
    """v2.1 - Search for bullish divergence and return the price at the reversal point."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def score_long_term_squeeze(*args, **kwargs):
    """Analysis and scoring of long-term compression signals v3.0 - With "Memory".
This function evaluates the quality of the entire accumulation period, not just the last candle."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def check_reversal_patterns_at_support(df: pd.DataFrame, timeframe_name: str) -> Tuple[int, List[str]]:
    """Check for bullish reversal candlestick patterns (Hammer, Piercing) that appear near the support zone."""
    score = 0
    reasons = []
    if df is None or len(df) < 5 or (not all((c in df.columns for c in ['cdl_hammer', 'cdl_piercing', 'low', 'bb_lower', 'ema_50']))):
        return (0, [])
    for i in range(1, 4):
        if len(df) <= i:
            continue
        candle = df.iloc[-i]
        is_hammer = candle['cdl_hammer'] == 100
        is_piercing = candle['cdl_piercing'] == 100
        if not (is_hammer or is_piercing):
            continue
        support_levels = {'d·∫£i BB d∆∞·ªõi': candle['bb_lower'], 'EMA 50': candle['ema_50']}
        pattern_name = 'Hammer' if is_hammer else 'Piercing Line'
        for support_name, support_price in support_levels.items():
            if support_price > 0 and abs(candle['low'] - support_price) / candle['low'] < 0.005:
                reason = f'N·∫øn {pattern_name} {timeframe_name} t·∫°i {support_name}'
                if reason not in reasons:
                    score += 15
                    reasons.append(reason)
    return (score, reasons)

def check_oversold_oscillator(df: pd.DataFrame, timeframe_name: str) -> Tuple[int, List[str]]:
    """Check out the buy signal from Stochastic as it crosses up from the oversold zone."""
    score = 0
    reasons = []
    if df is None or len(df) < 3 or (not all((c in df.columns for c in ['slowk', 'slowd']))):
        return (0, [])
    last = df.iloc[-1]
    prev = df.iloc[-2]
    is_crossover_in_oversold = prev['slowk'] < 25 and prev['slowd'] < 25 and (last['slowk'] > last['slowd']) and (prev['slowk'] < prev['slowd'])
    if is_crossover_in_oversold:
        score += 10
        reasons.append(f'Stochastic {timeframe_name} c·∫Øt l√™n t·ª´ v√πng qu√° b√°n')
    return (score, reasons)

def score_trending_pullback_setup(*args, **kwargs):
    """Module specializing in scoring the "Trending-Pullback" strategy.
(v2.1 - Optimize performance, prevent timeouts)"""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def analyze_breakout_volume_quality(df: pd.DataFrame, breakout_candle_index: int) -> Dict[str, Any]:
    """Analyze the Volume quality of a breakout.
- Check the spike of breakout candles.
- Check the follow-through of the volume in the next candle."""
    if breakout_candle_index < 1 or breakout_candle_index >= len(df) - 1:
        return {'is_quality': False, 'score_impact': 0, 'reason': 'D·ªØ li·ªáu kh√¥ng ƒë·ªß'}
    breakout_candle = df.iloc[breakout_candle_index]
    confirmation_candle = df.iloc[breakout_candle_index + 1]
    is_spike = breakout_candle['volume'] > breakout_candle['vol_ma_20'] * 2.5
    is_sustained = confirmation_candle['volume'] > breakout_candle['vol_ma_20'] * 1.5
    score_impact = 0
    reasons = []
    if is_spike:
        score_impact += 15
        reasons.append('Volume breakout ƒë·ªôt bi·∫øn')
    else:
        score_impact -= 30
        reasons.append('Volume breakout y·∫øu')
    if is_sustained:
        score_impact += 20
        reasons.append('Volume x√°c nh·∫≠n duy tr√¨ t·ªët')
    else:
        score_impact -= 40
        reasons.append('C·∫¢NH B√ÅO: Volume t·∫Øt ng·∫•m sau breakout')
    return {'is_quality': is_spike and is_sustained, 'score_impact': score_impact, 'reason': ' | '.join(reasons)}

def find_bearish_divergence(*args, **kwargs):
    """Look for negative divergence on the current timeframe.
Returns (True, reason) if found."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def _synthesize_market_extremes(*args, **kwargs):
    """"EXPERT COUNCIL" v1.0 - Synthesize signals to identify potential Tops/Bottoms.

This function acts as a high-level brain, taking opinions from many experts
different analyzes to come up with a single view of market possibilities
is at an important critical point.

Returns:
    A dictionary contains conclusions, confidence points, and collected evidence."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def analyze_breakout_structure(*args, **kwargs):
    """Breakout structure analysis v2.0 - Integrated "Distance Filter".
- Disable the "Breakout-Pre" signal if the current price has fallen too far
  away from the resistance zone, avoid waiting for useless signals."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def score_breakout_setup(data_1h: pd.DataFrame) -> Dict[str, Any]:
    """Module specializing in scoring for Breakout v4.0 - Using "Intelligence Memory".
This function calls the structural analyzer to make decisions based on context."""
    if data_1h is None or len(data_1h) < 50:
        return {'score': 0, 'reasons': [], 'strategy_tag': None}
    structure_analysis = analyze_breakout_structure(data_1h)
    score = structure_analysis.get('score', 0)
    reasons = structure_analysis.get('reasons', [])
    stage = structure_analysis.get('stage')
    strategy_tag = None
    if not structure_analysis.get('is_valid', False):
        return {'score': 0, 'reasons': reasons, 'strategy_tag': None}
    if stage == 'CONSOLIDATING':
        strategy_tag = 'Breakout-Pre'
    elif stage in ['BREAKOUT_ATTEMPT', 'CONFIRMED_HOLD']:
        strategy_tag = 'Instant-Explosion'
    else:
        return {'score': 0, 'reasons': reasons, 'strategy_tag': None}
    has_divergence, div_reason = find_bearish_divergence(data_1h)
    if has_divergence:
        score -= 60
        reasons.append(f'C·∫¢NH B√ÅO: {div_reason}')
    if score < 30:
        return {'score': 0, 'reasons': reasons, 'strategy_tag': strategy_tag}
    return {'score': score, 'reasons': reasons, 'strategy_tag': strategy_tag}

def find_double_bottom_pattern(*args, **kwargs):
    """Early detection of Double Bottom - W Pattern.
This is a very early bullish reversal signal."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def find_triple_bottom_pattern(*args, **kwargs):
    """Early detection of the Triple Bottom pattern.
This is an enhanced and more reliable version of Double Bottom."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def detect_kumo_twist(*args, **kwargs):
    """Detection of an impending bullish Kumo Twist, an early warning signal.
Add stronger points if the Clouds at the twist point are thin."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def _measure_downward_momentum(*args, **kwargs):
    """"CONTEXT RECORDER" v1.1 (Loosened)

Measure the recent decline to provide context. After integrating the EMA7 filter,
This function no longer plays the VETO role but only applies a slight penalty."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def _find_significant_recent_low(df: pd.DataFrame, lookback: int=20) -> Optional[Dict[str, Any]]:
    """"SHORT-TERM MEMORY" - Searching for an important "bottom event" in the recent past.

This function scans the most recent candle 'lookback' to determine the lowest low and
returns detailed information about it, including price, location, and elapsed time.

Returns:
    A dictionary containing information about the bottom, or None if not found."""
    if df is None or len(df) < lookback:
        return None
    recent_df = df.tail(lookback)
    low_idx_in_recent = recent_df['low'].idxmin()
    bottom_candle = recent_df.loc[low_idx_in_recent]
    candles_ago = len(recent_df) - recent_df.index.get_loc(low_idx_in_recent) - 1
    if 1 <= candles_ago <= lookback - 5:
        return {'price': bottom_candle['low'], 'candle': bottom_candle, 'index': low_idx_in_recent, 'candles_ago': candles_ago}
    return None

def _assess_recovery_strength(df: pd.DataFrame, low_index: pd.Timestamp) -> Dict[str, Any]:
    """"STRENGTH GAUGE" - Evaluates the quality of the recovery after a bottom is formed.

This function analyzes candles SINCE the "bottom event" for evidence
shows that buyers are returning.

Returns:
    A dictionary containing the score and reason for the healing power."""
    recovery_df = df[df.index > low_index]
    if recovery_df.empty:
        return {'score': -30, 'reasons': ['Ch∆∞a c√≥ d·∫•u hi·ªáu h·ªìi ph·ª•c']}
    score = 0
    reasons = []
    num_candles = len(recovery_df)
    green_candles = (recovery_df['close'] > recovery_df['open']).sum()
    green_ratio = green_candles / num_candles
    if green_ratio >= 0.6:
        score += 25
        reasons.append(f'H·ªìi ph·ª•c t·ªët ({green_candles}/{num_candles} n·∫øn xanh)')
    elif green_ratio < 0.4:
        score -= 20
        reasons.append(f'H·ªìi ph·ª•c y·∫øu ({green_candles}/{num_candles} n·∫øn xanh)')
    last_recovery_candle = recovery_df.iloc[-1]
    if last_recovery_candle['close'] > last_recovery_candle['ema_9']:
        score += 15
        reasons.append('Gi√° ƒë√£ l·∫•y l·∫°i EMA 9')
    if last_recovery_candle['close'] > last_recovery_candle['tenkan_sen']:
        score += 10
        reasons.append('Gi√° ƒë√£ v∆∞·ª£t Tenkan-sen')
    if last_recovery_candle['rsi'] > 45:
        score += 10
        reasons.append('RSI ƒë√£ tho√°t kh·ªèi v√πng nguy hi·ªÉm')
    return {'score': score, 'reasons': reasons}

def _analyze_ema7_positioning(df: pd.DataFrame, timeframe_name: str) -> Dict[str, Any]:
    """"VELOCITY SENSOR" EMA7 v2.1 - Integrated Overtaking Quality Analysis.

Analyze the price's position relative to the EMA7 to evaluate short-term momentum.
- VETO (Veto): If ALL THE LAST 3 CANDLES ARE BELOW EMA7, this is
  The "falling knife" sign with its immediate downward momentum is very strong and will be vetoed.
- ADDITIONAL POINTS (Advanced): Add high bonus points (+25) if an overshot is detected
  on EMA7 confirmed by both BLUE CANDLE and STRONG VOLUME.
  The function will check the last 2 candles for this high quality signal."""
    if df is None or len(df) < 5 or 'ema_7' not in df.columns or ('vol_ma_20' not in df.columns):
        return {'score_impact': 0, 'reason': ''}
    VETO_LOOKBACK = 3
    last_three_candles = df.tail(VETO_LOOKBACK)
    all_three_below = (last_three_candles['close'] < last_three_candles['ema_7']).all()
    if all_three_below:
        score_impact = -50
        reason = f'VETO (Dao R∆°i): C·∫£ {VETO_LOOKBACK} n·∫øn cu·ªëi ƒë·ªÅu d∆∞·ªõi EMA7 {timeframe_name}'
        return {'score_impact': score_impact, 'reason': reason}
    for i in range(1, 3):
        if len(df) <= i + 1:
            continue
        candle_to_check = df.iloc[-i]
        candle_before_that = df.iloc[-(i + 1)]
        is_crossover = candle_before_that['close'] < candle_before_that['ema_7'] and candle_to_check['close'] > candle_to_check['ema_7']
        is_green_candle = candle_to_check['close'] > candle_to_check['open']
        has_strong_volume = candle_to_check.get('volume', 0) > candle_to_check.get('vol_ma_20', 0) * 1.5
        if is_crossover and is_green_candle and has_strong_volume:
            score_impact = 25
            candle_age = 'hi·ªán t·∫°i' if i == 1 else 'tr∆∞·ªõc ƒë√≥'
            reason = f'‚úÖ V∆∞·ª£t EMA7 {timeframe_name} (N·∫øn {candle_age} xanh, vol m·∫°nh)'
            return {'score_impact': score_impact, 'reason': reason}
    return {'score_impact': 0, 'reason': ''}

def _apply_reversal_safety_filter(*args, **kwargs):
    """"SECURITY GATE" for Bottom Picking Strategy (v1.0).

This function applies a strict VETO filter to reversal signals:
1. VETO if 1H price is below EMA7.
2. EXEMPT VETO only if RSI(21) above 1H < 35 (confirming exhaustion).

Returns:
    (is_vetoed, reason) - Tuple containing the VETO flag and reason."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def _find_reversal_opportunity(data_1h: pd.DataFrame) -> Optional[Dict[str, Any]]:
    """"REVERSIBLE TRIGGER" v1.1 - 2-level RSI system.

This function scans for bottom fishing opportunities with higher sensitivity:
1. STRONG OVER SELL SIGNAL (RSI < 35): Strong signal, high basic point.
2. EARLY WARNING SIGNAL (35 <= RSI < 38): Weaker signal, lower base point.
3. RECENT SIGNAL: A significant bottom has formed within the past 12 candles.

Returns:
    A dictionary containing information about the signal if found, otherwise returns None."""
    if data_1h is None or len(data_1h) < 20:
        return None
    last_candle = data_1h.iloc[-1]
    current_rsi = last_candle['rsi']
    if current_rsi < 35:
        return {'type': 'OVERSOLD_RSI', 'reason': f'üî• RSI 1H ƒëang qu√° b√°n m·∫°nh ({current_rsi:.1f})', 'event_candle': last_candle, 'event_index': last_candle.name, 'base_score': 30}
    elif current_rsi < 38:
        return {'type': 'OVERSOLD_RSI', 'reason': f'‚è≥ RSI 1H ti·∫øn v√†o v√πng y·∫øu ({current_rsi:.1f})', 'event_candle': last_candle, 'event_index': last_candle.name, 'base_score': 20}
    bottom_event = _find_significant_recent_low(data_1h, lookback=12)
    if bottom_event:
        candles_ago = bottom_event['candles_ago']
        reason_str = f'ƒê√°y h√¨nh th√†nh c√°ch ƒë√¢y {candles_ago} n·∫øn 1H'
        base_score = 40 if candles_ago <= 3 else 25
        return {'type': 'RECENT_LOW', 'reason': reason_str, 'event_candle': bottom_event['candle'], 'event_index': bottom_event['index'], 'base_score': base_score}
    return None

def score_reversal_setup(pair: str, data_4h: pd.DataFrame, data_1h: pd.DataFrame, data_5m: pd.DataFrame) -> Dict[str, Any]:
    """Scoring module "Reversal-Scout" v6.0 - DISCONTINUED.

UPDATE:
- This function has been disabled.
- Bottom fishing logic now relies ONLY on detecting patterns
  Double Bottom and Triple Bottom in the `analyze_and_score` function.
- This complies with the new strategy requirement: only enter orders when there is a clear bottom structure."""
    return {'score': 0, 'reasons': []}

def analyze_and_score(*args, **kwargs):
    """General analysis function v6.9 - In-depth Bottom Catching by Pattern.

UPDATE:
- Completely removed calling the old `score_reversal_setup` function (based on RSI).
- "Reversal-Scout" strategy is now only triggered by detection functions
  `find_triple_bottom_pattern` and `find_double_bottom_pattern`,
  Make sure only signals with a clear bottom structure are considered."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def assess_short_term_health(*args, **kwargs):
    """v3.0 - Introduce "Tactical Posture" instead of just "Good/Risky"."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def calculate_success_probability(*args, **kwargs):
    """Estimate the probability of success of a combat plan based on all factors."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def run_scan() -> Dict[str, Any]:
    print('--- B·∫Øt ƒë·∫ßu phi√™n qu√©t m·ªõi ---')
    exchange = initialize_exchange(EXCHANGE)
    if not exchange:
        return {'recommendations': [], 'summary': {}}
    pairs, scan_summary, tickers = get_all_usdt_pairs(exchange)
    market_context = scan_summary.get('market_context', {})
    if not pairs:
        print('Kh√¥ng t√¨m th·∫•y c·∫∑p giao d·ªãch n√†o ƒë·ªÉ qu√©t.')
        return {'recommendations': [], 'summary': scan_summary}
    print('ƒêang t·∫£i d·ªØ li·ªáu BTC ƒë·ªÉ ph√¢n t√≠ch S·ª©c M·∫°nh T∆∞∆°ng ƒê·ªëi...')
    btc_data_4h = fetch_ohlcv_data(exchange, BTC_SYMBOL, '4h', 300)
    btc_data_1h = fetch_ohlcv_data(exchange, BTC_SYMBOL, '1h', 300)
    if btc_data_1h is None or btc_data_4h is None:
        print('C·∫¢NH B√ÅO: Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu BTC, ph√¢n t√≠ch RS s·∫Ω b·ªã b·ªè qua.')
        btc_data_4h, btc_data_1h = (pd.DataFrame(), pd.DataFrame())
    results, total_pairs = ([], len(pairs))
    print(f'\nB·∫Øt ƒë·∫ßu qu√° tr√¨nh qu√©t v√† ph√¢n t√≠ch s√¢u {total_pairs} m·ª•c ti√™u...')
    for i, pair in enumerate(pairs):
        print(f'  Radar ƒëang qu√©t m·ª•c ti√™u m·ªõi: {pair:<15} ({i + 1}/{total_pairs})', end='\r')
        data_1w = fetch_ohlcv_data(exchange, pair, '1w', 300)
        data_1d = fetch_ohlcv_data(exchange, pair, '1d', 300)
        data_4h = fetch_ohlcv_data(exchange, pair, '4h', 300)
        data_1h = fetch_ohlcv_data(exchange, pair, '1h', 300)
        data_15m = fetch_ohlcv_data(exchange, pair, '15m', 300)
        data_5m = fetch_ohlcv_data(exchange, pair, '5m', 300)
        data_4h = add_relative_strength_data(data_4h, btc_data_4h)
        data_1h = add_relative_strength_data(data_1h, btc_data_1h)
        data_1w = calculate_indicators(data_1w)
        data_1d = calculate_indicators(data_1d)
        data_4h = calculate_indicators(data_4h)
        data_1h = calculate_indicators(data_1h)
        data_15m = calculate_indicators(data_15m)
        data_5m = calculate_indicators(data_5m)
        if any((d is None or d.empty or len(d) < 2 for d in [data_4h, data_1h, data_15m, data_5m])):
            continue
        ticker_info = tickers.get(pair)
        current_price = ticker_info.get('last') if ticker_info else None
        recommendation = analyze_and_score(pair, data_1w, data_1d, data_4h, data_1h, data_15m, data_5m, market_context, current_price, minimum_score=1)
        if recommendation:
            results.append(recommendation)
    print('\nQu√©t m·ªõi ho√†n t·∫•t.' + ' ' * 40)
    sorted_results = sorted(results, key=lambda x: x['final_score'], reverse=True)
    scan_summary['found_targets'] = len(sorted_results)
    return {'recommendations': sorted_results, 'summary': scan_summary}

def analyze_specific_pairs(pairs_to_analyze: List[str]) -> List[Dict[str, Any]]:
    if not pairs_to_analyze:
        return []
    print(f"\n--- B·∫Øt ƒë·∫ßu ph√¢n t√≠ch l·∫°i {len(pairs_to_analyze)} m·ª•c ti√™u t·ª´ 'B·ªô Nh·ªõ' ---")
    exchange = initialize_exchange(EXCHANGE)
    if not exchange:
        return []
    market_context = analyze_market_context(exchange)
    try:
        tickers = exchange.fetch_tickers()
    except Exception:
        tickers = {}
        print('C·∫£nh b√°o: Kh√¥ng th·ªÉ t·∫£i tickers khi ph√¢n t√≠ch l·∫°i, s·∫Ω kh√¥ng c√≥ gi√° hi·ªán t·∫°i.')
    print('ƒêang t·∫£i d·ªØ li·ªáu BTC ƒë·ªÉ ph√¢n t√≠ch l·∫°i S·ª©c M·∫°nh T∆∞∆°ng ƒê·ªëi...')
    btc_data_4h = fetch_ohlcv_data(exchange, BTC_SYMBOL, '4h', 300)
    btc_data_1h = fetch_ohlcv_data(exchange, BTC_SYMBOL, '1h', 300)
    if btc_data_1h is None or btc_data_4h is None:
        print('C·∫¢NH B√ÅO: Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu BTC, ph√¢n t√≠ch RS s·∫Ω b·ªã b·ªè qua.')
        btc_data_4h, btc_data_1h = (pd.DataFrame(), pd.DataFrame())
    results, total_pairs = ([], len(pairs_to_analyze))
    for i, pair in enumerate(pairs_to_analyze):
        print(f'  ƒê√°nh gi√° l·∫°i (B·ªô nh·ªõ): {pair:<15} ({i + 1}/{total_pairs})', end='\r')
        data_1w = fetch_ohlcv_data(exchange, pair, '1w', 300)
        data_1d = fetch_ohlcv_data(exchange, pair, '1d', 300)
        data_4h = fetch_ohlcv_data(exchange, pair, '4h', 300)
        data_1h = fetch_ohlcv_data(exchange, pair, '1h', 300)
        data_15m = fetch_ohlcv_data(exchange, pair, '15m', 300)
        data_5m = fetch_ohlcv_data(exchange, pair, '5m', 300)
        data_4h = add_relative_strength_data(data_4h, btc_data_4h)
        data_1h = add_relative_strength_data(data_1h, btc_data_1h)
        data_1w = calculate_indicators(data_1w)
        data_1d = calculate_indicators(data_1d)
        data_4h = calculate_indicators(data_4h)
        data_1h = calculate_indicators(data_1h)
        data_15m = calculate_indicators(data_15m)
        data_5m = calculate_indicators(data_5m)
        if any((d is None or d.empty or len(d) < 2 for d in [data_4h, data_1h, data_15m, data_5m])):
            continue
        ticker_info = tickers.get(pair)
        current_price = ticker_info.get('last') if ticker_info else None
        recommendation = analyze_and_score(pair, data_1w, data_1d, data_4h, data_1h, data_15m, data_5m, market_context, current_price, minimum_score=1)
        if recommendation:
            results.append(recommendation)
    print("\nƒê√°nh gi√° l·∫°i 'B·ªô nh·ªõ' ho√†n t·∫•t." + ' ' * 40)
    return results

def _evaluate_15m_health(pair: str, data_15m: pd.DataFrame) -> Optional[Dict[str, Any]]:
    if data_15m is None or data_15m.empty or len(data_15m) < 50:
        return None
    if 'ma_trend' not in data_15m.columns:
        data_15m = calculate_indicators(data_15m)
        if data_15m is None:
            return None
    last = data_15m.iloc[-1]
    cond_price_above_ma = last['close'] > last['ma_trend']
    cond_ma_rising = last['ma_trend_rising']
    cond_adx_trending = last['adx'] > 20 and last['plus_di'] > last['minus_di']
    cond_rsi_healthy = last['rsi'] > 45
    cond_bearish_engulfing = last['cdl_engulfing'] == -100
    cond_high_volume_dump = last['close'] < last['open'] and last['volume'] > last['vol_ma_20'] * 2.0
    if cond_price_above_ma and cond_ma_rising and cond_adx_trending and cond_rsi_healthy:
        if cond_bearish_engulfing or cond_high_volume_dump:
            return {'pair': pair, 'status': 'Weak', 'reason': 'C·∫•u tr√∫c tƒÉng gi√° t·ªët nh∆∞ng xu·∫•t hi·ªán n·∫øn gi·∫£m m·∫°nh.'}
        return {'pair': pair, 'status': 'Good', 'reason': f'Gi√° tr√™n MA d·ªëc l√™n, ADX {last['adx']:.0f} x√°c nh·∫≠n xu h∆∞·ªõng tƒÉng.'}
    else:
        reasons = []
        if not cond_price_above_ma:
            reasons.append('gi√° d∆∞·ªõi MA')
        if not cond_ma_rising:
            reasons.append('MA ƒëi ngang/gi·∫£m')
        if not cond_adx_trending:
            reasons.append(f'ADX y·∫øu ({last['adx']:.0f})')
        if not cond_rsi_healthy:
            reasons.append(f'RSI y·∫øu ({last['rsi']:.0f})')
        return {'pair': pair, 'status': 'Weak', 'reason': f'C·∫•u tr√∫c suy y·∫øu: {', '.join(reasons)}.'}

def analyze_open_trades(open_trade_pairs: List[str]) -> Dict[str, Optional[Dict[str, Any]]]:
    if not open_trade_pairs:
        return {}
    print(f'\n--- B·∫Øt ƒë·∫ßu ƒë√°nh gi√° t√¨nh tr·∫°ng 15m c·ªßa {len(open_trade_pairs)} l·ªánh ƒëang m·ªü ---')
    exchange = initialize_exchange(EXCHANGE)
    if not exchange:
        return {pair: {'status': 'Weak', 'reason': 'L·ªói k·∫øt n·ªëi s√†n.'} for pair in open_trade_pairs}
    analysis_results, total_pairs = ({}, len(open_trade_pairs))
    for i, pair in enumerate(open_trade_pairs):
        print(f'  ƒê√°nh gi√° (L·ªánh m·ªü 15m): {pair:<15} ({i + 1}/{total_pairs})', end='\r')
        data_15m = fetch_ohlcv_data(exchange, pair, '15m', 300)
        if data_15m is None or len(data_15m) < 100:
            analysis_results[pair] = {'status': 'Weak', 'reason': 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu 15m.'}
            continue
        data_15m = calculate_indicators(data_15m)
        health_assessment = _evaluate_15m_health(pair, data_15m)
        analysis_results[pair] = health_assessment
    print('\nƒê√°nh gi√° l·ªánh ƒëang m·ªü ho√†n t·∫•t.' + ' ' * 40)
    return analysis_results

def analyze_15m_warhorse_potential(df_15m: pd.DataFrame) -> Dict[str, Any]:
    if df_15m is None or len(df_15m) < 100:
        return {'is_warhorse': False, 'score': 0, 'reason': ''}
    if 'ema_200' not in df_15m.columns or 'vol_ma_20' not in df_15m.columns:
        return {'is_warhorse': False, 'score': 0, 'reason': ''}
    last_15m = df_15m.iloc[-1]
    prev_15m = df_15m.iloc[-2]
    is_perfect_ema_order = last_15m['close'] > last_15m['ema_21'] > last_15m['ema_50'] > last_15m['ema_200']
    is_ema_rising = last_15m['ema_50'] > prev_15m['ema_50']
    if not (is_perfect_ema_order and is_ema_rising):
        return {'is_warhorse': False, 'score': 0, 'reason': ''}
    score = 20
    reasons = ['C·∫•u tr√∫c EMA 15m ho√†n h·∫£o']
    if last_15m['rsi'] > 58:
        score += 10
        reasons.append(f'RSI m·∫°nh ({last_15m['rsi']:.0f})')
    if last_15m['adx'] > 23:
        score += 10
        reasons.append(f'ADX x√°c nh·∫≠n trend ({last_15m['adx']:.0f})')
    df_15m['vol_ma_100'] = ta.SMA(df_15m['volume'], timeperiod=100)
    if not df_15m['vol_ma_100'].empty and last_15m['vol_ma_20'] > df_15m['vol_ma_100'].iloc[-1] * 1.2:
        score += 15
        reasons.append('D√≤ng ti·ªÅn ƒëang v√†o')
    recent_50_candles = df_15m.tail(50)
    green_candles_ratio = (recent_50_candles['close'] > recent_50_candles['open']).sum() / 50
    if green_candles_ratio > 0.6:
        score += 15
        reasons.append(f'Mua √°p ƒë·∫£o ({green_candles_ratio * 100:.0f}% n·∫øn xanh)')
    if score > 30:
        return {'is_warhorse': True, 'score': score, 'reason': ' | '.join(reasons)}
    return {'is_warhorse': False, 'score': 0, 'reason': ''}

def _find_significant_swing_low(data: pd.DataFrame, lookback: int=20) -> Optional[float]:
    """Find the nearest important Swing Low point."""
    df = data.tail(lookback).copy()
    if len(df) < 5:
        return None
    try:
        from scipy.signal import find_peaks
        troughs, _ = find_peaks(-df['low'], distance=3, width=1)
        if len(troughs) > 0:
            return df['low'].iloc[troughs[-1]]
    except (ImportError, Exception):
        pass
    df['swing_low'] = (df['low'] < df['low'].shift(1)) & (df['low'] < df['low'].shift(2)) & (df['low'] < df['low'].shift(-1)) & (df['low'] < df['low'].shift(-2))
    significant_lows = df[df['swing_low']]['low']
    if not significant_lows.empty:
        return significant_lows.iloc[-1]
    return df['low'].min()

def _find_nearest_resistance(entry_price: float, data_1h: pd.DataFrame, data_4h: pd.DataFrame) -> float:
    """Find the nearest reliable resistance area."""
    resistances = []
    recent_data_1h = data_1h.tail(150)
    highs_above_entry = recent_data_1h[recent_data_1h['high'] > entry_price * 1.005]['high']
    if not highs_above_entry.empty:
        s = highs_above_entry.sort_values()
        clusters = s[s.diff() < entry_price * 0.005]
        if not clusters.empty:
            resistances.append(clusters.mean())
        else:
            resistances.append(highs_above_entry.min())
    recent_data_4h = data_4h.tail(100)
    potential_resistances_4h = recent_data_4h[recent_data_4h['high'] > entry_price * 1.005]['high']
    if not potential_resistances_4h.empty:
        resistances.append(potential_resistances_4h.min())
    return min(resistances) if resistances else float('inf')

def _assess_reversal_context(*args, **kwargs):
    """"Market Sensor" function to differentiate between Panic Sell-Offs and Regular Corrections.

Analyze the most recent candle 'lookback' to assess the context of a reversal signal.

Returns:
    A tuple containing (context_type, reason_string).
    context_type can be: "PANIC_SELL", "SHARP_CORRECTION", "NORMAL_CORRECTION"."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def calculate_trade_parameters(*args, **kwargs):
    """Function to calculate transaction parameters v12.2 - Fix logic error SL > Entry.

UPDATE:
- Fix SL calculation logic error for Breakout/Squeeze strategy. Instead of placing SL at
  midpoint of the accumulation zone, SL will now be safely placed
  BELOW the bottom of the consolidation zone (consolidation_low), secure SL
  always lower than Entry.
- Tweaked SL logic for Trending-Pullback to ensure it is always below
  important support levels."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def format_15m_trade_status_telegram(trade_analysis: Dict[str, Optional[Dict[str, Any]]]) -> str:
    import html
    timestamp = datetime.now().strftime('%d/%m/%Y %H:%M:%S')
    message = f'üì° <b>B√°o C√°o Gi√°m S√°t L·ªánh (15m)</b> üì°\n<i>{timestamp}</i>\n\n'
    if not trade_analysis:
        message += '<i>- Kh√¥ng c√≥ l·ªánh n√†o ƒëang m·ªü ƒë·ªÉ gi√°m s√°t.</i>\n'
        return message
    good_trades, weak_trades, unknown_trades = ([], [], [])
    stance_emojis = {'T·∫§N C√îNG': '‚öîÔ∏è', 'PH√íNG TH·ª¶': 'üõ°Ô∏è', 'TI√äU CHU·∫®N': '‚öñÔ∏è'}
    for pair, analysis in trade_analysis.items():
        pair_safe = html.escape(pair)
        if not analysis or 'status' not in analysis:
            unknown_trades.append(pair_safe)
            continue
        status = analysis.get('status')
        reason = html.escape(analysis.get('reason', 'Kh√¥ng r√µ l√Ω do.'))
        open_rate = analysis.get('open_rate', 0.0)
        current_price = analysis.get('current_rate')
        sl = analysis.get('sl')
        tp1 = analysis.get('tp1')
        tp2 = analysis.get('tp2')
        stance = analysis.get('tactical_stance', 'TI√äU CHU·∫®N')
        stance_emoji = stance_emojis.get(stance, '‚öôÔ∏è')
        profit_emoji = '‚ö™'
        profit_str = 'N/A'
        if current_price and open_rate and (open_rate > 0):
            profit_pct = (current_price - open_rate) / open_rate * 100
            profit_abs = current_price - open_rate
            if profit_pct > 0.05:
                profit_emoji = 'üü¢'
            elif profit_pct < -0.05:
                profit_emoji = 'üî¥'
            if abs(profit_abs) > 1:
                abs_decimals = 2
            elif abs(profit_abs) > 0.1:
                abs_decimals = 4
            else:
                abs_decimals = 6
            profit_str = f'{profit_pct:+.2f}% ({profit_abs:+.{abs_decimals}f}$)'
        else:
            profit_pct_raw = analysis.get('profit_pct', 0.0) * 100
            if profit_pct_raw > 0:
                profit_emoji = 'üü¢'
            elif profit_pct_raw < 0:
                profit_emoji = 'üî¥'
            profit_str = f'{profit_pct_raw:+.2f}% (API)'
        price_for_decimal_check = open_rate or current_price or 0.0
        if price_for_decimal_check > 100:
            decimals = 2
        elif price_for_decimal_check > 10:
            decimals = 3
        elif price_for_decimal_check > 0.1:
            decimals = 4
        else:
            decimals = 6
        entry_price_str = f'{open_rate:.{decimals}f}'
        current_price_str = f'{current_price:.{decimals}f}' if current_price else 'N/A'
        trade_line = ''
        if status == 'Good':
            trade_line += f'‚úÖ <code>{pair_safe:<12}</code> <b>T·ªêT</b> ({stance} {stance_emoji})\n'
        elif status == 'Weak':
            trade_line += f'‚ö†Ô∏è <code>{pair_safe:<12}</code> <b>SUY Y·∫æU</b> ({stance} {stance_emoji})\n'
        trade_line += f'   - <b>L√£i/L·ªó: {profit_emoji} {profit_str}</b>\n   - <b>Gi√° Mua:</b> <code>{entry_price_str}</code> | <b>Hi·ªán t·∫°i:</b> <code>{current_price_str}</code>'
        if sl and tp1 and current_price and (current_price > 0):
            sl_dist_pct = (current_price - sl) / current_price * 100
            tp1_dist_pct = (tp1 - current_price) / current_price * 100
            sl_str = f'{sl:.{decimals}f}'
            tp1_str = f'{tp1:.{decimals}f}'
            plan_line = f'\n   - <b>K·∫ø Ho·∫°ch:</b> üõ°Ô∏è SL <code>{sl_str}</code> (c√°ch {sl_dist_pct:.1f}%) | üéØ TP1 <code>{tp1_str}</code> (c·∫ßn {tp1_dist_pct:.1f}%)'
            if tp2 and tp2 > tp1:
                tp2_dist_pct = (tp2 - current_price) / current_price * 100
                tp2_str = f'{tp2:.{decimals}f}'
                plan_line += f' | üöÄ TP2 <code>{tp2_str}</code> (c·∫ßn {tp2_dist_pct:.1f}%)'
            trade_line += plan_line
        assessment_text = f'<i>ƒê√°nh gi√°: {reason}</i>'
        if status == 'Weak':
            assessment_text += ' <b>C√¢n nh·∫Øc d·ªùi SL!</b>'
        trade_line += f'\n   - {assessment_text}'
        if status == 'Good':
            good_trades.append(trade_line)
        elif status == 'Weak':
            weak_trades.append(trade_line)
        else:
            unknown_trades.append(pair_safe)
    if good_trades:
        message += '<b><u>üëç L·ªánh Tr·∫°ng Th√°i T·ªët:</u></b>\n' + '\n\n'.join(good_trades) + '\n\n'
    if weak_trades:
        message += '<b><u>üö® L·ªánh C·∫ßn Ch√∫ √ù (Suy Y·∫øu):</u></b>\n' + '\n\n'.join(weak_trades) + '\n\n'
    if unknown_trades:
        message += '<b><u>‚ùì L·ªánh Kh√¥ng Th·ªÉ ƒê√°nh Gi√°:</u></b>\n' + '<code>' + ', '.join(unknown_trades) + '</code>\n'
    message += '\n<i>(ƒê√¢y l√† b√°o c√°o t·ª± ƒë·ªông t·ª´ T·ªï Gi√°m S√°t 15m)</i>'
    return message

def generate_plan_for_unmanaged_trade(*args, **kwargs):
    """Dedicated function to analyze and create a plan for an order that has been opened manually.
Version 2.1: Integrated Fallback mechanism to always create a plan even when there is no ideal setup.
- If the main analyzer does not find a strategy, it will switch to backup mode,
  Use basic market structure (swing low) to suggest SL and calculate TP accordingly."""
    '[PROPRIETARY LOGIC HIDDEN]\n---------------------------------------------------------\nThis function contains advanced algorithmic logic for:\n- Pattern Recognition & Signal Processing\n- Dynamic Risk Management (DEFCON System)\n- Automated Trade Execution\n\nThe implementation details and specific parameters have been\nremoved to protect Intellectual Property (IP).\n---------------------------------------------------------'
    pass

def main():
    print(f'--- C·ªë V·∫•n T√°c Chi·∫øn v5.1 (Ch·∫°y th·ªß c√¥ng) ---')
    print('\n\n--- [TEST] CH·ª®C NƒÇNG QU√âT TO√ÄN DI·ªÜN (H√ÄNG GI·ªú) ---')
    print(f'B·∫Øt ƒë·∫ßu qu√©t tr√™n s√†n {EXCHANGE} l√∫c {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}')
    scan_data = run_scan()
    sorted_results = scan_data.get('recommendations', [])
    print('\n\n--- K·∫æT QU·∫¢ QU√âT TH·ªä TR∆Ø·ªúNG & D·ª∞ B√ÅO T√ÅC CHI·∫æN ---')
    if not sorted_results:
        print('Kh√¥ng ph√°t hi·ªán m·ª•c ti√™u ti·ªÅm nƒÉng n√†o cho c√°c chi·∫øn l∆∞·ª£c ƒë√£ ch·ªçn t·∫°i th·ªùi ƒëi·ªÉm n√†y.')
        return
    emoji_map = {'Instant-Explosion': 'üí•', 'Breakout-Pre': '‚è≥', 'Reversal-Scout': 'üéØ', 'Trending-Pullback': 'üåä', '15m-Warhorse': 'üê¥', 'Long-Term-Squeeze': 'üíé'}
    print(f'\nTop {TOP_N_RESULTS} m·ª•c ti√™u c√≥ ƒëi·ªÉm cao nh·∫•t:\n')
    for i, res in enumerate(sorted_results[:TOP_N_RESULTS]):
        rank, pair, score = (i + 1, res['pair'], res['final_score'])
        strategy = res.get('strategy_type', 'N/A')
        emoji = emoji_map.get(strategy, 'üîπ')
        reason = res.get('reason', 'Kh√¥ng c√≥ l√Ω do.')
        print(f'--- H·∫°ng {rank}: {emoji} {pair} | ƒêi·ªÉm: {score:.0f} | Chi·∫øn l∆∞·ª£c: {strategy} ---')
        prob_check = res.get('probability_check')
        if prob_check:
            print(f'  [X√°c Su·∫•t Th·∫Øng]: {prob_check.get('probability_percent', 0):.1f}% ({prob_check.get('verdict', 'N/A')})')
        print(f'  [L√Ω do]: {reason}')
        if res.get('current_price'):
            print(f'  [Gi√° Hi·ªán T·∫°i]: {res['current_price']}')
        if 'entry' in res and 'sl' in res and ('tp1' in res) and ('tp2' in res):
            entry, sl, tp1, tp2 = (res['entry'], res['sl'], res['tp1'], res['tp2'])
            if entry > 10:
                decimals = 3
            elif entry > 0.1:
                decimals = 4
            else:
                decimals = 6
            risk = entry - sl
            if risk > 0:
                rr1, rr2 = ((tp1 - entry) / risk, (tp2 - entry) / risk)
                print(f'  [K·∫ø Ho·∫°ch]: Mua: {entry:.{decimals}f} | SL: {sl:.{decimals}f} | TP1: {tp1:.{decimals}f} (R:R ~1:{rr1:.1f}) | TP2: {tp2:.{decimals}f} (R:R ~1:{rr2:.1f})')
        else:
            print('  [K·∫ø Ho·∫°ch]: Kh√¥ng c√≥ tham s·ªë giao d·ªãch ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t.')
        print('-' * 80)
if __name__ == '__main__':
    main()